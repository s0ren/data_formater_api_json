"""Some functions for parsing a FIT file (specifically, a FIT file
generated by a Garmin vívoactive 3) and creating a Pandas DataFrame
with the data.
"""

from datetime import datetime, timedelta
from typing import Dict, Union, Optional,Tuple, List
import pytz

# import pandas as pd

import fitdecode

# The names of the columns we will use in our points DataFrame. For the data we will be getting
# from the FIT data, we use the same name as the field names to make it easier to parse the data.
POINTS_COLUMN_NAMES = ['latitude', 'longitude', 
                       'altitude', 'timestamp', 'heart_rate', 
                       'cadence', 
                       ]

# The names of the columns we will use in our laps DataFrame. 
LAPS_COLUMN_NAMES = ['number', 'start_time', 
                     'message_index', 'lap_trigger',
                     ]

def get_fit_lap_data(frame: fitdecode.records.FitDataMessage) -> Dict[str, Union[float, datetime, timedelta, int]]:
    """Extract some data from a FIT frame representing a lap and return
    it as a dict.
    """

    data: Dict[str, Union[float, datetime, timedelta, int]] = {}
    
    for field in LAPS_COLUMN_NAMES[1:]:  # Exclude 'number' (lap number) because we don't get that
                                        # from the data but rather count it ourselves
        if frame.has_field(field):
            data[field] = frame.get_value(field)

    return data

def get_fit_point_data(frame: fitdecode.records.FitDataMessage) -> Optional[Dict[str, Union[float, int, str, datetime]]]:
    """Extract some data from an FIT frame representing a track point
    and return it as a dict.
    """

    data: Dict[str, Union[float, int, str, datetime]] = {}

    if not (frame.has_field('position_lat') and frame.has_field('position_long')):
        # Frame does not have any latitude or longitude data. We will ignore these frames in order to keep things
        # simple, as we did when parsing the TCX file.
        return None
    else:
        data['latitude'] = frame.get_value('position_lat') / ((2**32) / 360)
        data['longitude'] = frame.get_value('position_long') / ((2**32) / 360)

    for field in POINTS_COLUMN_NAMES[2:]:
        if frame.has_field(field):
            data[field] = frame.get_value(field)
    if 'timestamp' in data:
        data['timestamp'] = data['timestamp'].astimezone(pytz.timezone('Europe/Copenhagen'))
    
    return data

def read_laps(fname: str) -> List:
    points_data = []
    laps_data = []
    lap_no = 1
    with fitdecode.FitReader(fname) as fit_file:
        for frame in fit_file:
            if isinstance(frame, fitdecode.records.FitDataMessage):
                if frame.name == 'record':
                    single_point_data = get_fit_point_data(frame)
                    if single_point_data is not None:
                        points_data.append(single_point_data)
                elif frame.name == 'lap':
                    single_lap_data = get_fit_lap_data(frame)
                    single_lap_data['number'] = lap_no
                    single_lap_data['points'] = points_data
                    laps_data.append(single_lap_data)
                    lap_no += 1
                    points_data = []
        return laps_data

def read_points(fname: str) -> List:
    points_data = []
    with fitdecode.FitReader(fname) as fit_file:
        for frame in fit_file:
            if isinstance(frame, fitdecode.records.FitDataMessage):
                if frame.name == 'record':
                    single_point_data = get_fit_point_data(frame)
                    if single_point_data is not None:
                        points_data.append(single_point_data)
        return points_data

## SKAL IKKE UDFØRES DIREKTE
if __name__ == '__main__':
    pass

    fname = "data/intervalløb/C8JI1413.FIT"

    # laps = read_laps(fname)    
    points = read_points(fname)

    import pprint
    pp = pprint.PrettyPrinter(compact=True, width=60, depth=2)
    # pp = pprint.PrettyPrinter(compact=True, width=60, depth=4)
    # pp.pprint(laps[2:4])
    pp.pprint(points[10:12])

